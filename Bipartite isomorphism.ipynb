{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums_idxs_dict(sum_vector):\n",
    "    '''Function that returns a dictionary of the sums values and their indexes in sum vector'''\n",
    "    return {k:list(np.where(sum_vector == k)[0]) for k in np.unique(sum_vector)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_sum_idxs_double_dict(arr1, arr2):\n",
    "    '''\n",
    "    Function that returns double dictionary of axis, sum value and indexes permutations from\n",
    "    two arrays. It finds all the possible permutations between the arrays based on every\n",
    "    value of the vector sum.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr1, arr2: 2D numpy arrays\n",
    "        Equal dimension arrays to be compared and to extract the permuted indexes.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    s_ip: dictionary\n",
    "        Dictionary of dictionary. First key is the axis. Second keys are sums values, i.e.\n",
    "        integers. Values are possible permutations (2D numpy arrays) in array notation,\n",
    "        therefore if the array has only one column, this column represent a new permutation\n",
    "        for the case of unique sum values, and this permutation should be now permanent.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> new_a = np.array([[0, 1, 0, 1, 1],\n",
    "                          [1, 0, 1, 1, 0],\n",
    "                          [1, 1, 0, 0, 0],\n",
    "                          [0, 1, 1, 0, 1]])\n",
    "    >>> new_b = np.array([[1, 1, 0, 0, 1],\n",
    "                          [0, 1, 1, 1, 0],\n",
    "                          [0, 0, 0, 1, 1],\n",
    "                          [1, 0, 1, 1, 0]])\n",
    "    >>> axis_sum_idxs_double_dict(new_a, new_b)\n",
    "    {0: {2: array([[0, 2, 3, 4],\n",
    "             [0, 1, 2, 4]]), 3: array([[1],\n",
    "             [3]])}, 1: {2: array([[2],\n",
    "             [2]]), 3: array([[0, 1, 3],\n",
    "             [0, 1, 3]])}}\n",
    "    \n",
    "    To access for example the Cauchy array created by uncertainty in axis 0, this means columns\n",
    "    uncertainty, and created also by uncertainty in all the columns adding up to 2, we need:\n",
    "    \n",
    "    >>> axis_sum_idxs_double_dict(new_a, new_b)[0][2]\n",
    "    array([[0, 2, 3, 4],\n",
    "           [0, 1, 2, 4]])\n",
    "    '''\n",
    "    \n",
    "    def sums_idxspermutations_dict(arr1, arr2, ax):\n",
    "        '''Function that finds all the possible permutations between the arrays based on vector\n",
    "        sum values.'''\n",
    "        i = 0\n",
    "        keys1_list = list(sums_idxs_dict(np.sum(arr1, ax)).keys())\n",
    "        keys2_list = list(sums_idxs_dict(np.sum(arr2, ax)).keys())\n",
    "        assert keys1_list == keys2_list\n",
    "        s_ip = {}\n",
    "        sidsa1a_values = sums_idxs_dict(np.sum(arr1, ax)).values()\n",
    "        sidsa2a_values = sums_idxs_dict(np.sum(arr2, ax)).values()\n",
    "        for v, w in zip(sidsa1a_values, sidsa2a_values):\n",
    "            assert len(v) == len(w)\n",
    "            if ax == 0:\n",
    "                array_value = np.concatenate((np.array([v]), np.array([w])))\n",
    "            elif ax == 1:\n",
    "                array_value = np.concatenate((np.array([w]), np.array([v])))\n",
    "            s_ip[keys1_list[i]] = array_value\n",
    "            i += 1\n",
    "        return s_ip\n",
    "    \n",
    "    dict_of_dict = {}\n",
    "    for j in (0, 1):\n",
    "        dict_of_dict[j] = sums_idxspermutations_dict(arr1, arr2, ax=j)\n",
    "    return dict_of_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_degeneracies_unique_only(arr1, arr2, ax, unique_sum_value, prints=False):\n",
    "    '''\n",
    "    Function that finds the double degeneracy for unique values in two permuted matrices and\n",
    "    their associated possible permutations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr1, arr2: 2D numpy arrays\n",
    "        Equal dimension arrays to be analyzed through their permuted indexes.\n",
    "    ax: int\n",
    "        Axis where the unique values vector is present.\n",
    "    unique_sum_value: int\n",
    "        Unique sum value to which its associated cauchy column must be used for locating all\n",
    "        possible permutations for every matrix element type in the perpendicular dimensions.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    two_arrays_dict: dict\n",
    "        Dictionary of two 2D numpy arrays, one for each type of matrix element possible\n",
    "        permutations. First array for matrix element and assigned key 0, second array for\n",
    "        matrix element and assigned key 1. They are cauchy arrays for all the possible\n",
    "        permutations in the perpendicular dimension.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> new_a = np.array([[0, 1, 0, 1, 1],\n",
    "                          [1, 0, 1, 1, 0],\n",
    "                          [1, 1, 0, 0, 0],\n",
    "                          [0, 1, 1, 0, 1]])\n",
    "    >>> new_b = np.array([[1, 1, 0, 0, 1],\n",
    "                          [0, 1, 1, 1, 0],\n",
    "                          [0, 0, 0, 1, 1],\n",
    "                          [1, 0, 1, 1, 0]])\n",
    "                          \n",
    "    The unique column adding up to 3, with original column index 1 and permuted column index 3,\n",
    "    won't produce degeneracy in the rows for matrix element 0, which has original row index 1\n",
    "    and permuted row index 0. But his column will produce a triple degeneracy in the rows for\n",
    "    matrix element 1:\n",
    "                          \n",
    "    >>> obtain_degeneracies_unique_only(new_a, new_b, 0, 3)\n",
    "    {0: array([[0],\n",
    "            [1]]), 1: array([[1, 2, 3],\n",
    "            [0, 2, 3]])}\n",
    "            \n",
    "    Similarly, the unique row adding up to 2, will produce the following degeneracies in the\n",
    "    columns, where it is important to notice the difference in original and permuted\n",
    "    convention for rows or columns Cauchy arrays:\n",
    "            \n",
    "    >>> obtain_degeneracies_unique_only(new_a, new_b, 1, 2)\n",
    "    {0: array([[2, 3, 4],\n",
    "            [0, 1, 2]]), 1: array([[0, 1],\n",
    "            [3, 4]])}\n",
    "    '''\n",
    "\n",
    "    dict_of_dicts = axis_sum_idxs_double_dict(arr1, arr2)\n",
    "    cauchy_column = dict_of_dicts[ax][unique_sum_value]\n",
    "    if prints:\n",
    "        print(\"cauchy_column:\")\n",
    "        print(cauchy_column)\n",
    "    assert cauchy_column.shape == (2, 1)\n",
    "\n",
    "    arrs = [arr1, arr2]\n",
    "    zeros_idxs= []\n",
    "    ones_idxs= []\n",
    "    for a in (0, 1):\n",
    "        if ax == 0:\n",
    "            unique_vector = arrs[a][:, cauchy_column[a][0]]\n",
    "        elif ax == 1:\n",
    "            unique_vector = arrs[a][cauchy_column[1-a][0]]\n",
    "        zeros_idxs.append(np.where(unique_vector==0)[0])\n",
    "        ones_idxs.append(np.where(unique_vector==1)[0])\n",
    "        if prints:\n",
    "            print(\"\\na\", a)\n",
    "            print(\"cauchy_column[1-a][0]\", cauchy_column[1-a][0])\n",
    "            print(\"unique_vector\", unique_vector)\n",
    "            print(\"np.where(unique_vector==0)[0]\", np.where(unique_vector==0)[0])\n",
    "            print(\"zeros_idxs\", zeros_idxs)\n",
    "            print(\"np.where(unique_vector==1)[0]\", np.where(unique_vector==1)[0])\n",
    "            print(\"ones_idxs\", ones_idxs)\n",
    "    \n",
    "    two_arrays_dict = {}\n",
    "    two_arrays_dict[0] = np.concatenate(([zeros_idxs[1-ax]], [zeros_idxs[ax]]))\n",
    "    two_arrays_dict[1] = np.concatenate(([ones_idxs[1-ax]], [ones_idxs[ax]]))\n",
    "    return two_arrays_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_intersections(x, y):\n",
    "    '''\n",
    "    Function that finds all Cartesian product intersections between two partitions x and y\n",
    "    of the same set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y: lists\n",
    "        Lists of lists, or list of 1D numpy arrays. Flattened lists of x and y should be equal.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_s: list\n",
    "        List of 1D numpy arrays of all Cartesian product intersections between x and y.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> u = [[1, 2], [3, 4, 5], [6, 7, 8, 9, 10]]\n",
    "    >>> v = [[1, 3, 6, 7], [2, 4, 5, 8, 9, 10]]\n",
    "    >>> partition_intersections(u, v)\n",
    "    [array([1]),\n",
    "     array([2]),\n",
    "     array([3]),\n",
    "     array([4, 5]),\n",
    "     array([6, 7]),\n",
    "     array([ 8,  9, 10])] \n",
    "    \n",
    "    '''\n",
    "    flattened_x = np.sort(np.concatenate((x), axis=None))\n",
    "    flattened_y = np.sort(np.concatenate((y), axis=None))\n",
    "    assert (flattened_x == flattened_y).all()\n",
    "    all_s = []\n",
    "    for sx in x:\n",
    "        for sy in y:\n",
    "            ss = list(filter(lambda i:i in sx, sy))\n",
    "            if ss:\n",
    "                all_s.append(ss)#np.array(ss))\n",
    "    return all_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullaxis_uniqueonly_degeneracies_intersection(fullaxis_dict, uniqueonly_dict):\n",
    "    '''\n",
    "    Function that applies partition_intersections among rows or cauchy arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fullaxis_dict: dict\n",
    "        Dictionary of all sums and their indexes degeneracy for a given axis, obtained from\n",
    "        axis_sum_idxs_double_dict.\n",
    "    uniqueonly_dict: dict\n",
    "        Dictionary of both degeneracies for given unique sum in axis perpendicular to the\n",
    "        previous one, obtained from obtain_degeneracies_unique_only.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    final_list: list\n",
    "        List of Cauchy arrays with partially complete degeneracy for given axis.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> new_a = np.array([[0, 1, 0, 1, 1],\n",
    "                          [1, 0, 1, 1, 0],\n",
    "                          [1, 1, 0, 0, 0],\n",
    "                          [0, 1, 1, 0, 1]])\n",
    "    >>> new_b = np.array([[1, 1, 0, 0, 1],\n",
    "                          [0, 1, 1, 1, 0],\n",
    "                          [0, 0, 0, 1, 1],\n",
    "                          [1, 0, 1, 1, 0]])\n",
    "                          \n",
    "    If we want to find intersection of degeneracies due to all columns (axis 0), knowing the\n",
    "    degeneracies obtained due to rows (axis 1) with unique sum value 2, the respective Cauchy\n",
    "    arrays for columns are:\n",
    "    \n",
    "    >>> asiddnanb0 = axis_sum_idxs_double_dict(new_a, new_b)[0]\n",
    "    >>> oduonanb12 = obtain_degeneracies_unique_only(new_a, new_b, 1, 2)\n",
    "    >>> fullaxis_uniqueonly_degeneracies_intersection(asiddnanb0, oduonanb12)\n",
    "    [array([[2, 3, 4],\n",
    "            [0, 1, 2]]), array([[0],\n",
    "            [4]]), array([[1],\n",
    "            [3]])]\n",
    "    '''\n",
    "    \n",
    "    def dic_row(dic, row):\n",
    "        '''Function that contructs list of 1D numpy arrays (rows) from row of dictionary of\n",
    "        2D numpy arrays'''\n",
    "        return [arr[row] for arr in dic.values()]\n",
    "    \n",
    "    pdp0 = partition_intersections(dic_row(fullaxis_dict, 0), dic_row(uniqueonly_dict, 0))\n",
    "    pdp1 = partition_intersections(dic_row(fullaxis_dict, 1), dic_row(uniqueonly_dict, 1))\n",
    "    final_list = []\n",
    "    for m, n in zip(pdp0, pdp1):\n",
    "        final_list.append(np.concatenate(([m], [n])))\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_sum_values(sum_vector):\n",
    "    '''Function that returns the unique sum values for a given (row or column) sum vector'''\n",
    "    sid = sums_idxs_dict(sum_vector)\n",
    "    return [k for k, v in sid.items() if len(v)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def FINAL(a, b, prints=False):\n",
    "    partial_permutations_dict = {}\n",
    "    for j in (1, 0):\n",
    "        us_a = unique_sum_values(np.sum(a, axis=j))\n",
    "        us_b = unique_sum_values(np.sum(b, axis=j))\n",
    "        if prints:\n",
    "            print(\"\\nj\", j)\n",
    "            print(np.sum(a, axis=j), \"us_a:\", us_a)\n",
    "            print(np.sum(b, axis=j), \"us_b:\", us_b)\n",
    "        assert us_a == us_b\n",
    "        my_dict = {}\n",
    "        c = 0\n",
    "        p_p = []\n",
    "        for u in us_a:\n",
    "            asiddabj = axis_sum_idxs_double_dict(a, b)[1-j]\n",
    "            oduoabju = obtain_degeneracies_unique_only(a, b, j, u)\n",
    "            fa_uo_di = fullaxis_uniqueonly_degeneracies_intersection(asiddabj, oduoabju)\n",
    "            if prints:\n",
    "                print(\"u\", u)\n",
    "                print(\"fa_uo_di:\")\n",
    "                print(fa_uo_di)\n",
    "            my_dict[u] = fa_uo_di\n",
    "            c += 1\n",
    "            if c == 1:\n",
    "                p_p = my_dict[us_a[c-1]]\n",
    "            if c > 1:\n",
    "                t_dict = {}\n",
    "                for i in (0, 1):\n",
    "                    rows_minus1 = [sublist[i] for sublist in my_dict[us_a[c-1]]]\n",
    "                    rows_partial = [sublist[i] for sublist in p_p]\n",
    "                    t_dict[i] = partition_intersections(rows_minus1, rows_partial)\n",
    "                p_p = [np.concatenate(([m], [n])) for m, n in zip(t_dict[0], t_dict[1])]\n",
    "            if prints:\n",
    "                print(\"p_p\", p_p)\n",
    "        if p_p:\n",
    "            partial_permutations_dict[1-j] = p_p\n",
    "        else:\n",
    "            asiddabj = axis_sum_idxs_double_dict(a, b)[1-j]\n",
    "            partial_permutations_dict[1-j] = [v for v in asiddabj.values()]\n",
    "\n",
    "    return partial_permutations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_nonready_arrays(new_a, new_b, ab_dict, prints=False, prints_counter=False):\n",
    "    ready_arrays_dict = {}\n",
    "    nonready_arrays_dict = {}\n",
    "    for k, v in ab_dict.items():\n",
    "        nonready_arrays = []\n",
    "        if prints:\n",
    "            print(\"\\nk\", k)\n",
    "            print(\"v\", v)\n",
    "        r = n = 0\n",
    "        for w in v:\n",
    "            if w.shape[1] == 1:\n",
    "                r += 1\n",
    "                if prints:\n",
    "                    print(r, \"READY:\")\n",
    "                    print(w)\n",
    "                if r == 1:\n",
    "                    ready_array = w\n",
    "                    if prints:\n",
    "                        print(\"ready_array:\")\n",
    "                        print(ready_array)\n",
    "                else:\n",
    "                    ready_array = np.concatenate((ready_array, w), axis=1)\n",
    "                    if prints:\n",
    "                        print(\"ready_array:\")\n",
    "                        print(ready_array)\n",
    "            else:\n",
    "                n += 1\n",
    "                if prints:\n",
    "                    print(n, \"not ready:\")\n",
    "                    print(w)\n",
    "                    print(\"nonready_arrays\", nonready_arrays)\n",
    "                nonready_arrays.append(w)\n",
    "        if prints_counter:\n",
    "            print(\"Final counters (r: ready, n: not ready)\")\n",
    "            print(\"r:\", r)\n",
    "            print(\"n:\", n)\n",
    "        if r != 0:\n",
    "            ready_arrays_dict[k] = ready_array\n",
    "        if n != 0:\n",
    "            nonready_arrays_dict[k] = nonready_arrays\n",
    "    return ready_arrays_dict, nonready_arrays_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permuted_order_cauchy_to_python(arr, ax):\n",
    "    '''\n",
    "    Example\n",
    "    -------\n",
    "    >>> cauchy = np.array([[1, 0, 2, 3, 5],\n",
    "                           [0, 2, 3, 1, 5]]) \n",
    "    >>> poctpC = permuted_order_cauchy_to_python(cauchy, 1)\n",
    "    >>> poctpC    \n",
    "    array([2, 0, 3, 1, 5])\n",
    "    >>> poctpR = permuted_order_cauchy_to_python(cauchy, 0)\n",
    "    >>> poctpR\n",
    "    array([1, 3, 0, 2, 5])\n",
    "    '''\n",
    "    cauchy_order = arr[:, np.argsort(arr[1-ax])]\n",
    "    python_permutation_order = cauchy_order[ax]    \n",
    "    return python_permutation_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITERATIVE FUNCTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pythonic(s):\n",
    "    all_elements = defaultdict(list)\n",
    "    for i, ss in enumerate(s):\n",
    "        for elem in ss:\n",
    "            all_elements[elem].append(i)\n",
    "    reversed = defaultdict(list)\n",
    "    for k, v in all_elements.items():\n",
    "        reversed[frozenset(v)].append(k)\n",
    "    return reversed#.keys()#.values()#list(reversed.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dicts(to_update_ready_dict, to_update_nonready_dict, AA, BB, prints=False):\n",
    "    initial_ready_dict = copy.deepcopy(to_update_ready_dict)\n",
    "    tup = (to_update_nonready_dict[0][0], to_update_nonready_dict[1][0])\n",
    "    A = AA[tup[1][1]][:, tup[0][0]]\n",
    "    B = BB[tup[1][0]][:, tup[0][1]]\n",
    "    r_n_tuple = ready_nonready_arrays(A, B, FINAL(A, B))\n",
    "    ready_AB_dict = r_n_tuple[0]\n",
    "    nonready_AB_dict = r_n_tuple[1]\n",
    "    ready_sub_dict = {k: tup[k][np.arange(2)[:, None], ready_AB_dict[k]] for k in \n",
    "                      ready_AB_dict.keys()}\n",
    "    nonready_sub_dict = {k: [tup[k][np.arange(2)[:, None], v] for v in \n",
    "                             nonready_AB_dict[k]] for k in nonready_AB_dict.keys()}\n",
    "    if prints:\n",
    "        print(\"tup\", tup)\n",
    "        print(\"A:\")\n",
    "        print(A)\n",
    "        print(\"B:\")\n",
    "        print(B)\n",
    "        print(\"ready_sub_dict\", ready_sub_dict)\n",
    "        print(\"nonready_sub_dict\", nonready_sub_dict)\n",
    "\n",
    "    for ax in ready_sub_dict:\n",
    "        if prints:\n",
    "            print(\"AXIS ax\", ax, \"analysis for ready_sub_dict:\")\n",
    "            print(\"initial to_update_ready_dict[ax]\", to_update_ready_dict[ax])\n",
    "            print(\"ready_sub_dict[ax]\", ready_sub_dict[ax])\n",
    "        for col in ready_sub_dict[ax].T:\n",
    "            cauchy_col = np.reshape(col, (2, 1))\n",
    "            if not (to_update_ready_dict[ax] == cauchy_col).all(axis=0).any():\n",
    "                to_update_ready_dict[ax] = np.concatenate((to_update_ready_dict[ax],\n",
    "                                                           cauchy_col), axis=1)\n",
    "                if prints:\n",
    "                    print(\"to_update_ready_dict[ax]:\")\n",
    "                    print(to_update_ready_dict[ax])\n",
    "                    print(\"initial to_update_nonready_dict[ax]\", to_update_nonready_dict[ax])\n",
    "                nr0_bool = [cauchy_col[0] in arr[0] for arr in to_update_nonready_dict[ax]]\n",
    "                nr1_bool = [cauchy_col[1] in arr[1] for arr in to_update_nonready_dict[ax]]\n",
    "                assert nr0_bool.index(True) == nr1_bool.index(True)\n",
    "                true_arr_idx = nr0_bool.index(True)\n",
    "                arr_to_update = to_update_nonready_dict[ax][true_arr_idx]\n",
    "                #print(\"initial arr_to_update\", arr_to_update)\n",
    "                idxs = [(i, np.where(arr_to_update[i]==cauchy_col[i])[0][0]) for i in (0, 1)]\n",
    "                #print(\"idxs\", idxs)\n",
    "                atus0 = arr_to_update.shape[0]\n",
    "                atus1 = arr_to_update.shape[1]\n",
    "                idxs = [i*atus1+j for i, j in idxs]\n",
    "                #print(\"idxs\", idxs)\n",
    "                arr_to_update = np.delete(arr_to_update, idxs).reshape(atus0, atus1-1)\n",
    "                #print(\"final arr_to_update\", arr_to_update)\n",
    "                if arr_to_update.shape == (2, 1):\n",
    "                    to_update_ready_dict[ax] = np.concatenate((to_update_ready_dict[ax],\n",
    "                                                               arr_to_update), axis=1)\n",
    "                    to_update_nonready_dict[ax].pop(true_arr_idx)\n",
    "                    if prints:\n",
    "                        print(\"if, to_update_ready_dict instead:\")\n",
    "                        print(\"to_update_ready_dict[ax]\", to_update_ready_dict[ax])\n",
    "                        print(\"to_update_nonready_dict[ax]\", to_update_nonready_dict[ax])\n",
    "                else:\n",
    "                    to_update_nonready_dict[ax][true_arr_idx] = arr_to_update\n",
    "                    if prints:\n",
    "                        print(\"else, to_update_nonready_dict[ax] now:\")\n",
    "                        print(\"to_update_nonready_dict[ax]\", to_update_nonready_dict[ax])\n",
    "\n",
    "    for ax in nonready_sub_dict:\n",
    "        if prints:\n",
    "            print(\"AXIS ax\", ax, \"analysis for nonready_sub_dict:\")\n",
    "            print(\"initial to_update_nonready_dict[ax]\", to_update_nonready_dict[ax])\n",
    "            print(\"nonready_sub_dict[ax]\", nonready_sub_dict[ax])\n",
    "        nrdax0 = [a[0] for a in to_update_nonready_dict[ax]]\n",
    "        nrsdax0 = [a[0] for a in nonready_sub_dict[ax]]\n",
    "        nrdax1 = [a[1] for a in to_update_nonready_dict[ax]]\n",
    "        nrsdax1 = [a[1] for a in nonready_sub_dict[ax]]\n",
    "        PDP0 = [v for v in pythonic(nrdax0 + nrsdax0).values()]\n",
    "        PDP1 = [pythonic(nrdax1 + nrsdax1)[k] for k in pythonic(nrdax0 + nrsdax0).keys()]\n",
    "        new_list = []\n",
    "        for m, n in zip(PDP0, PDP1):\n",
    "            new_list.append(np.concatenate(([m], [n])))\n",
    "        idx_to_pop = []\n",
    "        for c, arr in enumerate(new_list):\n",
    "            if ((arr.shape == (2, 1)) and\n",
    "                not (to_update_ready_dict[ax] == arr).all(axis=0).any()):\n",
    "                to_update_ready_dict[ax] = np.concatenate((uto_update_ready_dict[ax], arr),\n",
    "                                                          axis=1)\n",
    "                if prints:\n",
    "                    print(\"To update in to_update_ready_dict[ax] the arr:\", arr)\n",
    "                    print(\"to_update_ready_dict[ax]:\")\n",
    "                    print(to_update_ready_dict[ax])\n",
    "                idx_to_pop.append(c)\n",
    "            elif (arr.shape == (2, 1)) and (to_update_ready_dict[ax] == arr).all(axis=0).any():\n",
    "                if prints:\n",
    "                    print(\"Already updated in to_update_ready_dict[ax] the arr:\", arr)\n",
    "                idx_to_pop.append(c)\n",
    "        for i, idx in enumerate(idx_to_pop):\n",
    "            new_list.pop(idx - i) #because when poping an index, it changes the future indexes\n",
    "        to_update_nonready_dict[ax] = new_list\n",
    "        if prints:\n",
    "            print(\"to_update_nonready_dict[ax]\", to_update_nonready_dict[ax])\n",
    "\n",
    "    breaker = False\n",
    "    if (np.array_equal(initial_ready_dict[0], to_update_ready_dict[0]) and\n",
    "        np.array_equal(initial_ready_dict[1], to_update_ready_dict[1])):\n",
    "        if prints:\n",
    "            print(\"There was no change in the last iteration therefore procedure stops here\")\n",
    "        breaker = True\n",
    "    return to_update_ready_dict, to_update_nonready_dict, breaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blablabla(A, B, prints=False):\n",
    "    ready_nonready_tuple = ready_nonready_arrays(A, B, FINAL(A, B))\n",
    "    ready_dict = ready_nonready_tuple[0]\n",
    "    nonready_dict = ready_nonready_tuple[1]\n",
    "    if prints:\n",
    "        print(\"ready_dict\", ready_dict)\n",
    "        print(\"nonready_dict\", nonready_dict)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if (0 in nonready_dict) and (1 in nonready_dict):\n",
    "        j = 0\n",
    "        while (nonready_dict[0]) and (nonready_dict[1]):\n",
    "            ready_dict, nonready_dict, br = update_dicts(ready_dict, nonready_dict, A, B,\n",
    "                                                         prints=prints)\n",
    "            if prints:\n",
    "                print(\"AND THE\", j, \"th nonready_dict OBTAINED IS\", nonready_dict)\n",
    "            if br == True:\n",
    "                break\n",
    "            j += 1\n",
    "\n",
    "    return ready_dict, nonready_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_indexes_permutations(arr):\n",
    "    '''\n",
    "    Example\n",
    "    -------\n",
    "    >>> all_indexes_permutations(np.reshape(np.arange(6), (2,3)))\n",
    "    array([[[0, 1, 2],\n",
    "            [3, 4, 5]],\n",
    "\n",
    "           [[0, 1, 2],\n",
    "            [3, 5, 4]],\n",
    "\n",
    "           [[0, 1, 2],\n",
    "            [4, 3, 5]],\n",
    "\n",
    "           [[0, 1, 2],\n",
    "            [4, 5, 3]],\n",
    "\n",
    "           [[0, 1, 2],\n",
    "            [5, 3, 4]],\n",
    "\n",
    "           [[0, 1, 2],\n",
    "            [5, 4, 3]]])\n",
    "    '''\n",
    "    assert arr.shape[0] == 2\n",
    "    cases_number = np.math.factorial(arr.shape[1])\n",
    "    multi_array = np.zeros((cases_number, arr.shape[0], arr.shape[1]), dtype=int)\n",
    "    j = 0\n",
    "    for i in it.permutations(arr[1]):\n",
    "        new_array = np.stack((arr[0], i))\n",
    "        multi_array[j] = new_array\n",
    "        j += 1\n",
    "    return multi_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "## Input dimensions of random matrix to create (rows, cols): dim\n",
    "## Input maximum number of brute force permutations to try: max_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (97, 101)\n",
    "max_perm = 200000 # less than 5 minutes in my laptop, try 50000 for fast results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The (random) input array a and its random permutation b (if you get an error, restart from here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(2, size=dim)\n",
    "ar = np.arange(a.shape[0])\n",
    "np.random.shuffle(ar)\n",
    "ac = np.arange(a.shape[1])\n",
    "np.random.shuffle(ac)\n",
    "b = a[ar][:,ac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOW we execute the full algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "urd, unrd = blablabla(a, b)#, prints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the row and colum indexes where we still have a degeneracy, a brute force approach is implemented, where every row in the cauchy array contributes with the factorial of its number of columns to the total, and it is calculated beforehand in brute_force_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165888"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dims = [arr.shape[1] for arr in [a for sublist in unrd.values() for a in sublist]]\n",
    "brute_force_permutations = np.prod(col_dims)\n",
    "brute_force_permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, when implementing the brute force permutations of the remaining degenerate indexes, the (unique) counter index where the permutation between a and b is found is called successful_permutation_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful_permutation_counter: 1057490\n",
      "Total number of performed brute force permutations: 2654208\n"
     ]
    }
   ],
   "source": [
    "if brute_force_permutations < max_perm:\n",
    "\n",
    "    aip0 = [all_indexes_permutations(arr) for arr in unrd[0]]\n",
    "    aip1 = [all_indexes_permutations(arr) for arr in unrd[1]]\n",
    "\n",
    "    c = 0\n",
    "    for j in it.product(*aip0):\n",
    "        perm0 = np.concatenate(j, axis=-1)\n",
    "        #print(perm0)\n",
    "        funrd = {}\n",
    "        for i in it.product(*aip1):\n",
    "            c += 1\n",
    "            #print(\"c\", c)\n",
    "            perm1 = np.concatenate(i, axis=-1)\n",
    "            #print(perm1)\n",
    "            funrd[0] = perm0\n",
    "            funrd[1] = perm1\n",
    "            #print(\"funrd\", funrd)\n",
    "            d2 = [urd, funrd]\n",
    "            d = {}\n",
    "            for k in urd.keys():\n",
    "                if k in funrd.keys():\n",
    "                    d[k] = np.hstack([dd[k] for dd in d2])\n",
    "                else:\n",
    "                    d[k] = urd[k]\n",
    "            poctpd11 = permuted_order_cauchy_to_python(d[1], 1)\n",
    "            poctpd00 = permuted_order_cauchy_to_python(d[0], 0)\n",
    "            p_a = a[poctpd11][:, poctpd00]\n",
    "            if (p_a == b).all():\n",
    "                print(\"SUCCESS!!!\")\n",
    "                successful_permutation_counter = c\n",
    "                print(\"successful_permutation_counter:\", successful_permutation_counter)\n",
    "                rows_permutation = permuted_order_cauchy_to_python(d[1], 1)\n",
    "                cols_permutation = permuted_order_cauchy_to_python(d[0], 0)\n",
    "    print(\"Total number of performed brute force permutations:\", c)\n",
    "    \n",
    "else:\n",
    "    print(\"Restart the matrices, the number of permutations is too large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, the required permutations in python indexing style are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 81, 61, 40, 12, 74,  8, 25, 13, 47, 68, 41, 59, 46, 83, 95, 22,\n",
       "       75, 33, 65, 63, 38, 52, 88, 48,  0, 92, 42, 35, 14, 39, 37, 69, 20,\n",
       "       85, 15,  9, 57, 19, 24, 43, 29, 55, 58, 77, 27, 73,  3,  7,  6,  4,\n",
       "       79, 34, 76, 56, 10,  5, 51, 31, 84, 53, 93, 17, 90, 18, 26, 94, 21,\n",
       "       50, 67, 91,  1, 86, 82, 36, 62, 60, 96, 78, 32, 89, 16, 71, 80,  2,\n",
       "       49, 11, 23, 64, 54, 30, 87, 45, 28, 70, 72, 66])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 57,  43,  53,  97,  85,  76,  27,  47,  15,  63,  93,  38,  19,\n",
       "        58,  21,  60,  36,  42,  40,  96,  35,  78,  91,  16,   9,  73,\n",
       "        82,  24,   2,  84,  98,  66,  32,  10, 100,  20,  89,   4,  67,\n",
       "         7,  69,  23,  41,  26,  39,  64,  14,  29,  75,   0,  77,  88,\n",
       "        44,  72,  48,   5,  54,  11,  56,  90,  80,  30,  18,  37,  92,\n",
       "        22,  62,  33,  50,  71,  61,  13,  94,  70,  74,  86,  34,  87,\n",
       "        99,  68,  55,  45,  51,  65,  17,  81,   3,  49,  59,  83,  25,\n",
       "         1,   8,  95,   6,  52,  28,  79,  31,  46,  12])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
